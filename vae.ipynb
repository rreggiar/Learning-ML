{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import h5py\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes after subsetting: 5676\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#reading in files\n",
    "X = pd.read_hdf(\"data/tcga_mutation_train.h5\", \"expression\")\n",
    "Y = pd.read_hdf('data/tcga_mutation_train.h5', 'labels')\n",
    "\n",
    "#L1000 subsetting\n",
    "l1000_file = open(\"L1000_clueio_genelist.txt\")\n",
    "l1000 = [i.strip() for i in l1000_file.readlines()]\n",
    "#get l1000 genes that are in data\n",
    "# L1000_= pd.Series(list(set(X.columns) & set(l1000)))\n",
    "# X_L1000 = X[L1000_] #subset X data\n",
    "\n",
    "# Prune expression to only KEGG pathway genes\n",
    "with open(\"data/c2.cp.kegg.v6.1.symbols.gmt\") as f:\n",
    "    genes_subset = list(set().union(*[line.strip().split(\"\\t\")[2:] for line in f.readlines()]))\n",
    "X_pruned = X.drop(labels=(set(X.columns) - set(genes_subset)), axis=1, errors=\"ignore\")\n",
    "\n",
    "#using both kegg and L1000\n",
    "subset_ = set(X_pruned.columns.tolist() + l1000)\n",
    "subset = pd.Series(list(set(X.columns) & set(subset_)))\n",
    "\n",
    "print(\"Number of genes after subsetting:\", len(subset))\n",
    "\n",
    "X_sub = X[subset] #subset X data\n",
    "\n",
    "\n",
    "x_array = np.array(X.values, dtype=np.float32)\n",
    "\n",
    "# extract sample id values\n",
    "y_names = list(set(Y[\"detailed_category\"].values))\n",
    "y_names = sorted(y_names)\n",
    "\n",
    "m,n = X.shape\n",
    "y_array = np.zeros(shape=(m, len(y_names)+3), dtype=np.float32)\n",
    "\n",
    "# create a key for id's to indices\n",
    "y_index_key = {name:i for i,name in enumerate(y_names)}\n",
    "# generate one-hot vectors for all id's\n",
    "for m,primary_site_name in enumerate(Y[\"detailed_category\"].values):\n",
    "    \n",
    "    index = y_index_key[primary_site_name]\n",
    "    y_array[m,index] = 1\n",
    "    \n",
    "    y_array[m, -3] = Y.iloc[m][6]\n",
    "    y_array[m, -2] = Y.iloc[m][7]\n",
    "    y_array[m, -1] = Y.iloc[m][8]\n",
    "    \n",
    "    \n",
    "#split to train + test\n",
    "xTrain, xTest, yTrain, yTest = sklearn.model_selection.train_test_split(X_sub, y_array, test_size=0.3, random_state=42)\n",
    "#split test to test and validate \n",
    "xTest, xValidate, yTest, yValidate = sklearn.model_selection.train_test_split(xTest, yTest, test_size=1/3, random_state=42)\n",
    "\n",
    "print(yTrain)\n",
    "xTrain = np.array(xTrain.values, dtype=np.float32)\n",
    "xTest = np.array(xTest.values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        x_dtype = torch.FloatTensor\n",
    "\n",
    "        self.length = x.shape[0]\n",
    "\n",
    "        self.x_data = torch.from_numpy(x).type(x_dtype)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.x_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "class PredictorDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        x_dtype = torch.FloatTensor\n",
    "        y_dtype = torch.FloatTensor\n",
    "        self.length = x.shape[0]\n",
    "\n",
    "        self.x_data = torch.from_numpy(x).type(x_dtype)\n",
    "        self.y_data = torch.from_numpy(y).type(y_dtype)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, len(x)), size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "def train_batch(model, x, y, optimizer, loss_fn):\n",
    "    # Run forward calculation\n",
    "    y_predict, avg, stdev = model.forward(x)\n",
    "\n",
    "    # Compute loss.\n",
    "    loss = loss_fn(y_predict, y)\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable weights\n",
    "    # of the model)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.data[0]\n",
    "\n",
    "\n",
    "def train(model, loader, optimizer, loss_fn, epochs=50):\n",
    "    losses = list()\n",
    "\n",
    "    batch_index = 0\n",
    "    for e in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x = Variable(x)\n",
    "            y = Variable(y)\n",
    "\n",
    "            loss = train_batch(model=model, x=x, y=y, optimizer=optimizer, loss_fn=loss_fn)\n",
    "            losses.append(loss)\n",
    "\n",
    "            batch_index += 1\n",
    "\n",
    "    model.training = False\n",
    "    return losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(model, loader):\n",
    "    y_vectors = list()\n",
    "    y_predict_vectors = list()\n",
    "\n",
    "    batch_index = 0\n",
    "    for x, y in loader:\n",
    "        x = Variable(x)\n",
    "        y = Variable(y)\n",
    "\n",
    "        y_predict = model.forward(x)\n",
    "\n",
    "        y_vectors.append(y.data.numpy())\n",
    "        y_predict_vectors.append(y_predict.data.numpy())\n",
    "\n",
    "        batch_index += 1\n",
    "\n",
    "    y_predict_vector = np.concatenate(y_predict_vectors)\n",
    "    \n",
    "    return y_predict_vector\n",
    "\n",
    "def encode(model, loader):\n",
    "    encoded_vectors = list()\n",
    "    for x, y in loader:\n",
    "        x = Variable(x)\n",
    "\n",
    "        encoded = model.encode(x)\n",
    "\n",
    "        encoded_vectors.append(encoded.data.numpy())\n",
    "\n",
    "    encoded_vector = np.concatenate(encoded_vectors)\n",
    "    return encoded_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    '''\n",
    "    A simple, general purpose, fully connected network\n",
    "    '''\n",
    "    def __init__(self, D_in, size1, size2):\n",
    "        # Perform initialization of the pytorch superclass\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        learning_rate = 1e-2\n",
    "        \n",
    "        \n",
    "        self.encode1 = nn.Linear(D_in, size1)\n",
    "        self.encodeAvg = nn.Linear(size1, size2)\n",
    "        self.encodeStdev = nn.Linear(size1, size2)\n",
    "        self.decode1 = nn.Linear(size2, size1)\n",
    "        self.decode2 = nn.Linear(size1, D_in)\n",
    "        \n",
    "        self.training = True\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        This method defines the network layering and activation functions\n",
    "        '''\n",
    "        x = self.encode1(x) # hidden layer\n",
    "        x = F.relu(x)       # activation function\n",
    "\n",
    "        avgs = self.encodeAvg(x) # output layer\n",
    "        stdevs = self.encodeStdev(x)\n",
    "\n",
    "        if self.training:\n",
    "            std = torch.exp(stdevs*0.5)\n",
    "            eps = torch.randn_like(std)\n",
    "            x = eps.mul(std).add_(avgs)\n",
    "        else:\n",
    "            x = avgs\n",
    "        x = self.decode1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.decode2(x)\n",
    "        x = F.sigmoid(x)\n",
    "            \n",
    "        return x, avgs, stdevs\n",
    "    \n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Return the trained hidden layer and encoded input\"\"\"\n",
    "        #Get the dataset\n",
    "        x = self.encode1(x) # hidden layer\n",
    "        x = F.relu(x)       # activation function\n",
    "\n",
    "        avg = self.encodeAvg(x)\n",
    "        return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "results logreg with autoencoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 43.609245  42.332302  17.849098 ... -20.197935  47.171535  57.64376 ]\n",
      " [ 45.133675  44.257214  19.395172 ... -20.76133   47.761932  58.92911 ]\n",
      " [ 42.214264  41.600704  17.631042 ... -22.246635  47.191742  54.873417]\n",
      " ...\n",
      " [ 44.112137  43.32668   18.295887 ... -20.394117  46.61047   56.95417 ]\n",
      " [ 44.99722   44.28259   19.709044 ... -21.51629   47.64371   58.676586]\n",
      " [ 42.438763  41.59054   17.090252 ... -22.740686  46.91838   54.797695]]\n",
      "[[ 43.769234  43.087967  18.492907 ... -21.341408  47.1753    56.954533]\n",
      " [ 46.445415  44.585003  19.936848 ... -20.649244  50.31336   61.256588]\n",
      " [ 42.98657   42.599304  18.150915 ... -20.90619   46.743748  57.02777 ]\n",
      " ...\n",
      " [ 43.688046  43.179302  18.408197 ... -19.658575  46.040817  56.077328]\n",
      " [ 43.64888   42.51991   19.536411 ... -19.284359  45.879665  57.135647]\n",
      " [ 41.1438    39.99937   17.127672 ... -20.064074  44.107513  54.111458]]\n",
      "% Correct with logreg and autoencoder:  56 56 [0.01408451 0.69131455 0.94131455 0.92899061]\n",
      "Elapsed time: 53.390228s\n",
      "[1] \"Glioblastoma Multiforme_F1_score: 0\"\n",
      "[1] \"Skin Cutaneous Melanoma_F1_score: 0\"\n",
      "[1] \"Head & Neck Squamous Cell Carcinoma_F1_score: 0\"\n",
      "[1] \"Breast Invasive Carcinoma_F1_score: 0\"\n",
      "[1] \"Lung Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Brain Lower Grade Glioma_F1_score: 0\"\n",
      "[1] \"Stomach Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Kidney Clear Cell Carcinoma_F1_score: 0\"\n",
      "[1] \"Liver Hepatocellular Carcinoma_F1_score: 0\"\n",
      "[1] \"Bladder Urothelial Carcinoma_F1_score: 0\"\n",
      "[1] \"Ovarian Serous Cystadenocarcinoma_F1_score: 0\"\n",
      "[1] \"Esophageal Carcinoma_F1_score: 0\"\n",
      "[1] \"Thyroid Carcinoma_F1_score: 0\"\n",
      "[1] \"Lung Squamous Cell Carcinoma_F1_score: 0\"\n",
      "[1] \"Uveal Melanoma_F1_score: 0\"\n",
      "[1] \"Kidney Papillary Cell Carcinoma_F1_score: 0\"\n",
      "[1] \"Sarcoma_F1_score: 0\"\n",
      "[1] \"Cervical & Endocervical Cancer_F1_score: 0\"\n",
      "[1] \"Mesothelioma_F1_score: 0\"\n",
      "[1] \"Acute Myeloid Leukemia_F1_score: 0.0277777777777778\"\n",
      "[1] \"Rectum Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Prostate Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Thymoma_F1_score: 0\"\n",
      "[1] \"Colon Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Pheochromocytoma & Paraganglioma_F1_score: 0\"\n",
      "[1] \"Kidney Chromophobe_F1_score: 0\"\n",
      "[1] \"Adrenocortical Cancer_F1_score: 0\"\n",
      "[1] \"Uterine Corpus Endometrioid Carcinoma_F1_score: 0\"\n",
      "[1] \"Uterine Carcinosarcoma_F1_score: 0\"\n",
      "[1] \"Pancreatic Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Testicular Germ Cell Tumor_F1_score: 0\"\n",
      "[1] \"Cholangiocarcinoma_F1_score: 0\"\n",
      "[1] \"Diffuse Large B-Cell Lymphoma_F1_score: 0\"\n",
      "[1] \"Overall Tissue F1 score: 0.000841750841750842\"\n",
      "[1] \"TP53_F1_score: NaN\"\n",
      "[1] \"KRAS_F1_score: NaN\"\n",
      "[1] \"BRAF_F1_score: NaN\"\n",
      "[1] \"Mutation_F1_score: NaN\"\n",
      "[1] \"Final_F1_score: 0.000420875420875421\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11.822746  -22.453892    1.3451561 ...   2.2673273   7.1149135\n",
      "    4.022381 ]\n",
      " [ 10.626304  -22.241894    1.7177511 ...   1.7298213   6.9494796\n",
      "    3.5964346]\n",
      " [ 12.149093  -23.664679    2.151298  ...   1.5816927   8.170226\n",
      "    3.1366534]\n",
      " ...\n",
      " [ 12.228536  -23.67678     1.2457905 ...   1.3858209   8.772553\n",
      "    4.2169294]\n",
      " [ 12.045946  -22.03976     1.4207411 ...   2.6004062   7.821641\n",
      "    3.3476887]\n",
      " [ 10.930545  -21.635832    1.2464943 ...   2.738262    7.6873684\n",
      "    4.402821 ]]\n",
      "[[ 11.244427   -22.941414     2.1550422  ...   1.4575158    7.445836\n",
      "    4.0086617 ]\n",
      " [ 11.511886   -22.835665     2.0770574  ...   0.9462445    7.3714447\n",
      "    3.575005  ]\n",
      " [ 10.771533   -22.090097     1.5245533  ...   1.0035634    7.910443\n",
      "    3.427771  ]\n",
      " ...\n",
      " [ 10.181466   -20.889565     1.6641356  ...   2.3839657    7.311992\n",
      "    3.7379258 ]\n",
      " [ 10.8505125  -22.22744      1.5683513  ...   0.98852885   7.547903\n",
      "    3.5182896 ]\n",
      " [ 12.731482   -19.8488       1.2632952  ...  -0.03617124   7.402346\n",
      "    3.0561414 ]]\n",
      "% Correct with logreg and autoencoder:  4257 2838 [0.04342723 0.57453052 0.88673709 0.86150235]\n",
      "Elapsed time: 3045.476516s\n",
      "[1] \"Glioblastoma Multiforme_F1_score: 0\"\n",
      "[1] \"Skin Cutaneous Melanoma_F1_score: 0\"\n",
      "[1] \"Head & Neck Squamous Cell Carcinoma_F1_score: 0.0914285714285714\"\n",
      "[1] \"Breast Invasive Carcinoma_F1_score: 0.17632241813602\"\n",
      "[1] \"Lung Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Brain Lower Grade Glioma_F1_score: 0.0571428571428571\"\n",
      "[1] \"Stomach Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Kidney Clear Cell Carcinoma_F1_score: 0.0543478260869565\"\n",
      "[1] \"Liver Hepatocellular Carcinoma_F1_score: 0.0169491525423729\"\n",
      "[1] \"Bladder Urothelial Carcinoma_F1_score: 0\"\n",
      "[1] \"Ovarian Serous Cystadenocarcinoma_F1_score: 0.0153846153846154\"\n",
      "[1] \"Esophageal Carcinoma_F1_score: 0\"\n",
      "[1] \"Thyroid Carcinoma_F1_score: 0\"\n",
      "[1] \"Lung Squamous Cell Carcinoma_F1_score: 0.0330578512396694\"\n",
      "[1] \"Uveal Melanoma_F1_score: 0\"\n",
      "[1] \"Kidney Papillary Cell Carcinoma_F1_score: 0.0425531914893617\"\n",
      "[1] \"Sarcoma_F1_score: 0\"\n",
      "[1] \"Cervical & Endocervical Cancer_F1_score: 0.0363636363636364\"\n",
      "[1] \"Mesothelioma_F1_score: 0\"\n",
      "[1] \"Acute Myeloid Leukemia_F1_score: 0.027363184079602\"\n",
      "[1] \"Rectum Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Prostate Adenocarcinoma_F1_score: 0.0264900662251656\"\n",
      "[1] \"Thymoma_F1_score: 0\"\n",
      "[1] \"Colon Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Pheochromocytoma & Paraganglioma_F1_score: 0\"\n",
      "[1] \"Kidney Chromophobe_F1_score: 0\"\n",
      "[1] \"Adrenocortical Cancer_F1_score: 0\"\n",
      "[1] \"Uterine Corpus Endometrioid Carcinoma_F1_score: 0\"\n",
      "[1] \"Uterine Carcinosarcoma_F1_score: 0\"\n",
      "[1] \"Pancreatic Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Testicular Germ Cell Tumor_F1_score: 0\"\n",
      "[1] \"Cholangiocarcinoma_F1_score: 0\"\n",
      "[1] \"Diffuse Large B-Cell Lymphoma_F1_score: 0\"\n",
      "[1] \"Overall Tissue F1 score: 0.0234096600941557\"\n",
      "[1] \"TP53_F1_score: 0.300867888138862\"\n",
      "[1] \"KRAS_F1_score: 0.0853080568720379\"\n",
      "[1] \"BRAF_F1_score: 0.0166666666666667\"\n",
      "[1] \"Mutation_F1_score: 0.134379738051091\"\n",
      "[1] \"Final_F1_score: 0.0793088214933713\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-48.339447   9.480579  31.687338 ... -47.461308  33.4022   -11.69935 ]\n",
      " [-45.00673    9.562611  30.68357  ... -45.23989   31.38032  -10.079558]\n",
      " [-49.11628    8.180693  31.964169 ... -49.212383  33.816303 -11.609059]\n",
      " ...\n",
      " [-48.22629    9.070653  31.705486 ... -48.50416   33.956554 -11.285165]\n",
      " [-48.402885  10.218317  32.195633 ... -48.171852  33.910374 -12.186844]\n",
      " [-48.9361    10.406243  31.47539  ... -48.611446  33.236168 -11.881174]]\n",
      "[[-49.55973     9.076023   31.791264  ... -49.981194   33.879982\n",
      "  -12.875681 ]\n",
      " [-51.221573    9.43601    33.851303  ... -50.954205   34.820923\n",
      "  -12.266271 ]\n",
      " [-52.080593   10.457656   34.060135  ... -52.826122   36.903217\n",
      "  -12.222719 ]\n",
      " ...\n",
      " [-51.434452    8.923946   33.483887  ... -51.35469    35.245235\n",
      "  -12.18439  ]\n",
      " [-49.728653   10.213206   32.261322  ... -50.191597   34.098366\n",
      "  -12.903389 ]\n",
      " [-51.55493    10.0553055  33.572117  ... -51.21119    35.841896\n",
      "  -12.731243 ]]\n",
      "% Correct with logreg and autoencoder:  567 378 [0.01584507 0.65962441 0.94190141 0.92840376]\n",
      "Elapsed time: 285.047894s\n",
      "[1] \"Glioblastoma Multiforme_F1_score: 0\"\n",
      "[1] \"Skin Cutaneous Melanoma_F1_score: 0\"\n",
      "[1] \"Head & Neck Squamous Cell Carcinoma_F1_score: 0\"\n",
      "[1] \"Breast Invasive Carcinoma_F1_score: 0.019047619047619\"\n",
      "[1] \"Lung Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Brain Lower Grade Glioma_F1_score: 0\"\n",
      "[1] \"Stomach Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Kidney Clear Cell Carcinoma_F1_score: 0\"\n",
      "[1] \"Liver Hepatocellular Carcinoma_F1_score: 0\"\n",
      "[1] \"Bladder Urothelial Carcinoma_F1_score: 0\"\n",
      "[1] \"Ovarian Serous Cystadenocarcinoma_F1_score: 0.0227272727272727\"\n",
      "[1] \"Esophageal Carcinoma_F1_score: 0\"\n",
      "[1] \"Thyroid Carcinoma_F1_score: 0\"\n",
      "[1] \"Lung Squamous Cell Carcinoma_F1_score: 0\"\n",
      "[1] \"Uveal Melanoma_F1_score: 0\"\n",
      "[1] \"Kidney Papillary Cell Carcinoma_F1_score: 0.03125\"\n",
      "[1] \"Sarcoma_F1_score: 0\"\n",
      "[1] \"Cervical & Endocervical Cancer_F1_score: 0\"\n",
      "[1] \"Mesothelioma_F1_score: 0\"\n",
      "[1] \"Acute Myeloid Leukemia_F1_score: 0.0273646638905413\"\n",
      "[1] \"Rectum Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Prostate Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Thymoma_F1_score: 0\"\n",
      "[1] \"Colon Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Pheochromocytoma & Paraganglioma_F1_score: 0\"\n",
      "[1] \"Kidney Chromophobe_F1_score: 0\"\n",
      "[1] \"Adrenocortical Cancer_F1_score: 0\"\n",
      "[1] \"Uterine Corpus Endometrioid Carcinoma_F1_score: 0\"\n",
      "[1] \"Uterine Carcinosarcoma_F1_score: 0\"\n",
      "[1] \"Pancreatic Adenocarcinoma_F1_score: 0\"\n",
      "[1] \"Testicular Germ Cell Tumor_F1_score: 0\"\n",
      "[1] \"Cholangiocarcinoma_F1_score: 0\"\n",
      "[1] \"Diffuse Large B-Cell Lymphoma_F1_score: 0\"\n",
      "[1] \"Overall Tissue F1 score: 0.0374958832067902\"\n",
      "[1] \"TP53_F1_score: 0.0993788819875776\"\n",
      "[1] \"KRAS_F1_score: 0.0198019801980198\"\n",
      "[1] \"BRAF_F1_score: NaN\"\n",
      "[1] \"Mutation_F1_score: 0.0447316747798352\"\n",
      "[1] \"Final_F1_score: 0.0483047639577398\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def run_logreg(xtrain, ytrain, xtest, ytest, size1, size2, multi):\n",
    "    \n",
    "    dataset_train = PredictorDataset(x=xtrain, y=ytrain)\n",
    "    dataset_test = PredictorDataset(x=xtest, y=ytest)\n",
    "    dataset_train_encode = AutoencoderDataset(xtrain)\n",
    "    dataset_test_encode = AutoencoderDataset(xtest)\n",
    "    \n",
    "    # Batch size is the number of training examples used to calculate each iteration's gradient\n",
    "    batch_size_train = 16\n",
    "    \n",
    "    data_loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size_train, shuffle=True)\n",
    "    data_loader_train_encode = DataLoader(dataset=dataset_train_encode, batch_size=batch_size_train, shuffle=True)\n",
    "    data_loader_test = DataLoader(dataset=dataset_test, batch_size=len(dataset_test), shuffle=False)\n",
    "    data_loader_test_encode = DataLoader(dataset=dataset_test_encode, batch_size=batch_size_train, shuffle=True)\n",
    "    \n",
    "    # Define the hyperparameters\n",
    "    learning_rate = 1e-2\n",
    "\n",
    "    # Define the loss function\n",
    "    loss_fn = nn.MSELoss()  # mean squared error\n",
    "\n",
    "    # Train and get the resulting loss per iteration\n",
    "    #Train first autoencoder layer\n",
    "    encoder_model = VariationalAutoencoder(len(xtrain[0]), size1, size2)\n",
    "\n",
    "    # Initialize the optimizer with above parameters\n",
    "    optimizer = optim.SGD(encoder_model.parameters(), lr=learning_rate)\n",
    "    train(model=encoder_model, loader=data_loader_train_encode, optimizer=optimizer, loss_fn=loss_fn)\n",
    "    \n",
    "    newXTrain = encode(encoder_model,data_loader_train_encode)\n",
    "    newXTest = encode(encoder_model, data_loader_test_encode)\n",
    "    # Test and get the resulting predicted y values\n",
    "    aeLogRegModel = OneVsRestClassifier(LogisticRegression()).fit(newXTrain, ytrain)\n",
    "    \n",
    "    y_predict_ae = aeLogRegModel.predict(newXTest)\n",
    "    return y_predict_ae\n",
    "\n",
    "\n",
    "aeResults = []\n",
    "yActual = np.array([[y_names[np.argmax(vector[0:-3])], 1 if vector[-3]==1 else 0, 1 if vector[-2]==1 else 0, 1 if vector[-1]==1 else 0] for vector in yTest])\n",
    "sizes = [(int(len(xTest[0])/100), int(len(xTest[0])/100)), (int(len(xTest[0])*0.75), int(len(xTest[0])/2)), (int(len(xTest[0])/10), int(len(xTest[0])/15))]\n",
    "\n",
    "'''\n",
    "print(\"Results logreg without autoencoder:\")\n",
    "startTime = time.time()\n",
    "aeLogRegModel = OneVsRestClassifier(LogisticRegression()).fit(xTrain, np.array(yTrain))\n",
    "yPred = aeLogRegModel.predict(xTest)\n",
    "elapsedTime = time.time() - startTime\n",
    "yPred = np.array([[y_names[np.argmax(vector[0:-3])], 1 if vector[-3]>=0.5 else 0, 1 if vector[-2]>=0.5 else 0, 1 if vector[-1]>=0.5 else 0] for vector in yPred])\n",
    "\n",
    "isCorrect = [[yPred[i][j] == yActual[i][j] for j in range(len(yPred[0]))] for i in range(len(yPred))]\n",
    "\n",
    "\n",
    "numCorrect = np.sum(isCorrect, axis=0)\n",
    "\n",
    "pred0, act0 = [v[0] for v in yPred], [v[0] for v in yActual]\n",
    "pred1, act1 =  [int(v[1]) for v in yPred], [v[1] for v in yActual]\n",
    "pred2, act2 =  [int(v[2]) for v in yPred], [v[2] for v in yActual]\n",
    "pred3, act3 =  [int(v[3]) for v in yPred], [v[3] for v in yActual]\n",
    "\n",
    "##### Write output file and get f1 score\n",
    "pd.DataFrame({\n",
    "    \"TumorTypePrediction\": pred0,\n",
    "    \"TP53MutationPrediction\": pred1,\n",
    "    \"KRASMutationPrediction\": pred2,\n",
    "    \"BRAFMutationPrediction\": pred3,\n",
    "}).to_csv(\"test_predictions.tsv\", sep=\"\\t\")\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"primary.disease.or.tissue\": act0,\n",
    "    \"TP53_mutant\": act1,\n",
    "    \"KRAS_mutant\": act2,\n",
    "    \"BRAF_mutant\": act3,\n",
    "}).to_csv(\"test_actuals.tsv\", sep=\"\\t\")\n",
    "\n",
    "print(\"% Correct with logreg : \", (numCorrect/len(isCorrect)))\n",
    "print(\"Elapsed time: %f s\" % elapsedTime)\n",
    "!Rscript class/BME230_F1score_V2.R test_predictions.tsv test_actuals.tsv\n",
    "'''\n",
    "print()\n",
    "print(\"results logreg with autoencoder\")\n",
    "for size in sizes:\n",
    "    size1, size2 = size\n",
    "    \n",
    "    startTime = time.time()\n",
    "    yPred = run_logreg(xTrain, yTrain, xTest, yTest, size1, size2, True)\n",
    "    elapsedTime = time.time() - startTime\n",
    "    \n",
    "    yPred = np.array([[y_names[np.argmax(vector[0:-3])], 1 if vector[-3]>=0.5 else 0, 1 if vector[-2]>=0.5 else 0, 1 if vector[-1]>=0.5 else 0] for vector in yPred])\n",
    "\n",
    "    isCorrect = [[yPred[i][j] == yActual[i][j] for j in range(len(yPred[0]))] for i in range(len(yPred))]\n",
    "\n",
    "\n",
    "    numCorrect = np.sum(isCorrect, axis=0)\n",
    "\n",
    "    pred0, act0 = [v[0] for v in yPred], [v[0] for v in yActual]\n",
    "    pred1, act1 =  [int(v[1]) for v in yPred], [v[1] for v in yActual]\n",
    "    pred2, act2 =  [int(v[2]) for v in yPred], [v[2] for v in yActual]\n",
    "    pred3, act3 =  [int(v[3]) for v in yPred], [v[3] for v in yActual]\n",
    "\n",
    "    ##### Write output file and get f1 score\n",
    "    pd.DataFrame({\n",
    "        \"TumorTypePrediction\": pred0,\n",
    "        \"TP53MutationPrediction\": pred1,\n",
    "        \"KRASMutationPrediction\": pred2,\n",
    "        \"BRAFMutationPrediction\": pred3,\n",
    "    }).to_csv(\"test_predictions.tsv\", sep=\"\\t\")\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"primary.disease.or.tissue\": act0,\n",
    "        \"TP53_mutant\": act1,\n",
    "        \"KRAS_mutant\": act2,\n",
    "        \"BRAF_mutant\": act3,\n",
    "    }).to_csv(\"test_actuals.tsv\", sep=\"\\t\")\n",
    "\n",
    "    print(\"% Correct with logreg and autoencoder: \", size1, size2, (numCorrect/len(isCorrect)))\n",
    "    print(\"Elapsed time: %fs\" % elapsedTime)\n",
    "    !Rscript class/BME230_F1score_V2.R test_predictions.tsv test_actuals.tsv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
